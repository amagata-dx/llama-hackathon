# Llama API Key for AI analysis (SambaNova)
VITE_LLAMA_API_KEY=your_api_key_here

# Ollama Configuration (Local LLM Fallback)
# Set to false to disable Ollama fallback
VITE_OLLAMA_ENABLED=true
# Ollama API endpoint (default: http://localhost:11434)
VITE_OLLAMA_URL=http://localhost:11434
# Ollama model to use (default: llama3.2)
VITE_OLLAMA_MODEL=llama3.2